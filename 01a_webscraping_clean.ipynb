{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Webscraping Clean\n",
    "\n",
    "#### Rens og filtrér hentet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "reviewErrorCount = [] # used in multithreadwritecsvfile\n",
    "dataDir = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Henter valgte filer ind i en liste\n",
    "def loadRawData(*args):\n",
    "    allPagesRequest = []\n",
    "    for arg in args:\n",
    "        with open(dataDir+arg+'.dump','rb') as file:\n",
    "            allPagesRequest = allPagesRequest + pickle.load(file)\n",
    "    return allPagesRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frasortere emojis\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "# Frasortere linjeskift, comma, og dobbelt mellemrum & gør al tekst lowercase.\n",
    "def data_cleaning(data):\n",
    "    data = data.lower()\n",
    "    data = data.replace('\\r', ' ')\n",
    "    data = data.replace(\",\", ' ')\n",
    "    data = data.replace('\"', '')\n",
    "    data = data.replace('  ', '')\n",
    "    return data\n",
    "\n",
    "# Splitter hver url i listen, og returnere hjemmesidenavnet.\n",
    "def createFiles(url):\n",
    "    filename = str(url.url)\n",
    "    filename = filename.split('.')\n",
    "\n",
    "    if len(filename) == 4:\n",
    "        filename = filename[2].split('/')\n",
    "        filename = filename[2]\n",
    "    else:\n",
    "        filename = filename[3]\n",
    "    return filename\n",
    "\n",
    "# Tjekker om filen eksistere, så den ikke bliver appended til igen. \n",
    "def checkFileExists(filename):\n",
    "    try:\n",
    "        with open(filename,'rb') as file:\n",
    "            return 0\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtrere den gå data med bs4 og skriver til en csv med det navn som request url'et indholder.\n",
    "def multithreadwritecsvfile(page):\n",
    "    loadingbar.update(1)\n",
    "\n",
    "    filename = dataDir+createFiles(page)+'.csv'\n",
    "    \n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as output_file:\n",
    "        output_writer = csv.writer(output_file)\n",
    "        \n",
    "        soup = bs4.BeautifulSoup(page.content,'html.parser')\n",
    "        for content in soup.find_all('section', attrs={'class':'styles_reviewContentwrapper__zH_9M'}):\n",
    "            rating=None\n",
    "            splitted=None\n",
    "            review=None\n",
    "\n",
    "            try: \n",
    "                rating = content.find('img',alt = True)\n",
    "                splitted = rating.get('alt').split()\n",
    "            except Exception as e:\n",
    "                print('No rating found. Skipping...', e)\n",
    "\n",
    "            try: \n",
    "                review = content.find('p', attrs={'class':'typography_typography__QgicV typography_body__9UBeQ typography_color-black__5LYEn typography_weight-regular__TWEnf typography_fontstyle-normal__kHyN3'}).text\n",
    "                if len(review) > 2:\n",
    "                    review = remove_emojis(review)\n",
    "                    review = data_cleaning(review)\n",
    "                    if len(review) > 0:\n",
    "                        output_writer.writerow(['__label__'+splitted[2]+\" \", review])\n",
    "            except Exception as e:\n",
    "                reviewErrorCount.append(e);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Udskriv alle filer med en bestem extension\n",
    "def get_filenames(ext):\n",
    "    pathname = dataDir + '/*.' + ext\n",
    "    filenames = []\n",
    "    for file in glob.glob(pathname, recursive=True):\n",
    "        file = file.replace('.' + ext,'')\n",
    "        filenames.append(file.replace(dataDir,''))\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "# Merger alle csv sammen til én fil\n",
    "def mergeCsvFiles(filenames_input):\n",
    "\n",
    "    filenames = []\n",
    "    # loop through the list with filenames we want to merge\n",
    "    for name in filenames_input:\n",
    "        filenames.append(dataDir+name + '.csv')\n",
    "\n",
    "    #combine all the files\n",
    "    combinedCSV = pd.concat([pd.read_csv(f) for f in filenames])\n",
    "    print(filenames)\n",
    "    \n",
    "    #export to csv\n",
    "    combinedCSV.to_csv(dataDir+'combined_csv.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alfinans',\n",
       " 'asos',\n",
       " 'av-cables',\n",
       " 'boksen',\n",
       " 'cdon',\n",
       " 'computersalg',\n",
       " 'contourdesign',\n",
       " 'cphbusiness',\n",
       " 'eboligskoedet',\n",
       " 'elgiganten',\n",
       " 'ferratumbank',\n",
       " 'gamecastle',\n",
       " 'isports',\n",
       " 'jyskmobelfabrik',\n",
       " 'komplett',\n",
       " 'power',\n",
       " 'sas',\n",
       " 'tapeconnection',\n",
       " 'telia',\n",
       " 'thyrep',\n",
       " 'vestjyskbank']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames('dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPagesRequest = loadRawData(\n",
    " 'alfinans',\n",
    " 'asos',\n",
    " 'av-cables',\n",
    " 'boksen',\n",
    " 'cdon',\n",
    " 'computersalg',\n",
    " 'contourdesign',\n",
    " 'cphbusiness',\n",
    " 'eboligskoedet',\n",
    " 'elgiganten',\n",
    " 'ferratumbank',\n",
    " 'gamecastle',\n",
    " 'isports',\n",
    " 'jyskmobelfabrik',\n",
    " 'komplett',\n",
    " 'power',\n",
    " 'sas',\n",
    " 'tapeconnection',\n",
    " 'telia',\n",
    " 'thyrep',\n",
    " 'vestjyskbank'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shop in allPagesRequest:\n",
    "    filename = dataDir+createFiles(shop)+'.csv'\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        output_writer = csv.writer(output_file)\n",
    "        output_writer.writerow(['rating','review'])\n",
    "        \n",
    "with tqdm(total=len(allPagesRequest)) as loadingbar: \n",
    "    with ThreadPoolExecutor(2) as ex:\n",
    "        \n",
    "        ex.map(multithreadwritecsvfile, allPagesRequest)\n",
    "\n",
    "print('Done. Skipped reviews:', len(reviewErrorCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alfinans',\n",
       " 'asos',\n",
       " 'av-cables',\n",
       " 'boksen',\n",
       " 'cdon',\n",
       " 'combined_csv',\n",
       " 'computersalg',\n",
       " 'contourdesign',\n",
       " 'cphbusiness',\n",
       " 'eboligskoedet',\n",
       " 'elgiganten',\n",
       " 'ferratumbank',\n",
       " 'gamecastle',\n",
       " 'isports',\n",
       " 'jyskmobelfabrik',\n",
       " 'komplett',\n",
       " 'power',\n",
       " 'sas',\n",
       " 'sklearn',\n",
       " 'tapeconnection',\n",
       " 'telia',\n",
       " 'thyrep',\n",
       " 'vestjyskbank']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames('csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCsvFiles([\n",
    " 'alfinans',\n",
    " 'asos',\n",
    " 'av-cables',\n",
    " 'boksen',\n",
    " 'cdon',\n",
    " 'computersalg',\n",
    " 'contourdesign',\n",
    " 'cphbusiness',\n",
    " 'eboligskoedet',\n",
    " 'elgiganten',\n",
    " 'ferratumbank',\n",
    " 'gamecastle',\n",
    " 'isports',\n",
    " 'jyskmobelfabrik',\n",
    " 'komplett',\n",
    " 'power',\n",
    " 'sas',\n",
    " 'tapeconnection',\n",
    " 'telia',\n",
    " 'thyrep',\n",
    " 'vestjyskbank'\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
